2022/08/22 11:32:33 available device: cuda:0
2022/08/22 11:33:12 epoch_out: 0, epoch_in: 0, loss: 0.9958779662847519
2022/08/22 11:33:41 epoch_out: 0, epoch_in: 1, loss: 0.24065328296273947
2022/08/22 11:34:10 epoch_out: 0, epoch_in: 2, loss: 0.12238360214978457
2022/08/22 11:34:38 epoch_out: 0, epoch_in: 3, loss: 0.08637723522260785
2022/08/22 11:35:06 epoch_out: 0, epoch_in: 4, loss: 0.05031712166965008
2022/08/22 11:35:34 epoch_out: 0, epoch_in: 5, loss: 0.0058789638802409176
2022/08/22 11:36:02 epoch_out: 0, epoch_in: 6, loss: -0.02591226398944855
2022/08/22 11:36:30 epoch_out: 0, epoch_in: 7, loss: -0.06524657523259521
2022/08/22 11:36:58 epoch_out: 0, epoch_in: 8, loss: -0.11670466493815183
2022/08/22 11:37:26 epoch_out: 0, epoch_in: 9, loss: -0.15350101301446556
2022/08/22 11:37:26 The epoch_out: 0, epoch_in: 9 of training F and G finished, losslist: [0.9958779662847519, 0.24065328296273947, 0.12238360214978457, 0.08637723522260785, 0.05031712166965008, 0.0058789638802409176, -0.02591226398944855, -0.06524657523259521, -0.11670466493815183, -0.15350101301446556], acclist: [0, 0.44, 0.53, 0.495, 0.505, 0.515, 0.525, 0.5, 0.495, 0.48, 0.5, 0.485, 0.555, 0.54, 0.485, 0.52, 0.495, 0.505, 0.515, 0.51, 0.49, 0.49, 0.51, 0.52, 0.51, 0.515, 0.48, 0.475, 0.485, 0.49, 0.515, 0.52, 0.52, 0.49, 0.495, 0.515, 0.485, 0.485, 0.485, 0.475, 0.51, 0.52, 0.525, 0.53, 0.485, 0.495, 0.5, 0.525, 0.5, 0.48, 0.52, 0.47, 0.485, 0.515, 0.505, 0.43, 0.52, 0.515, 0.52, 0.495, 0.495, 0.49, 0.53, 0.5, 0.505, 0.485, 0.505, 0.515, 0.515, 0.505, 0.5, 0.52, 0.505, 0.525, 0.49, 0.515, 0.47, 0.475, 0.52, 0.53, 0.465, 0.525, 0.48, 0.47, 0.52, 0.46, 0.505, 0.5, 0.52, 0.5, 0.47, 0.53, 0.51, 0.485, 0.505, 0.49, 0.5, 0.51, 0.52, 0.485, 0.495, 0.475, 0.455, 0.515, 0.505, 0.49, 0.5, 0.53, 0.51, 0.48, 0.47, 0.52, 0.51, 0.52, 0.47, 0.5, 0.495, 0.495, 0.505, 0.47, 0.495, 0.515, 0.5, 0.51, 0.48, 0.485, 0.51, 0.47, 0.505, 0.475, 0.47, 0.49, 0.485, 0.465, 0.495, 0.505, 0.52, 0.48, 0.47, 0.56, 0.485, 0.49, 0.505, 0.495, 0.51, 0.495, 0.5, 0.49, 0.5, 0.49, 0.49, 0.51, 0.48, 0.47, 0.485, 0.485, 0.485, 0.49, 0.485, 0.51, 0.495, 0.49, 0.48, 0.51, 0.505, 0.5, 0.495, 0.49, 0.5, 0.515, 0.475, 0.48, 0.5, 0.475, 0.485, 0.515, 0.48, 0.485, 0.455, 0.465, 0.485, 0.51, 0.49, 0.51, 0.48, 0.505, 0.475, 0.505, 0.505, 0.495, 0.5, 0.47, 0.5, 0.485, 0.48, 0.475, 0.47, 0.51, 0.5, 0.515, 0.5, 0.52, 0.47, 0.505, 0.495, 0.5, 0.495, 0.49, 0.51, 0.51, 0.5, 0.475, 0.465, 0.5, 0.49, 0.49, 0.5, 0.5, 0.505, 0.52, 0.475, 0.48, 0.52, 0.465, 0.515, 0.515, 0.5, 0.515, 0.485, 0.515, 0.48, 0.485, 0.5, 0.49, 0.525, 0.475, 0.49, 0.515, 0.475, 0.505, 0.525, 0.465, 0.515, 0.495, 0.48, 0.47, 0.51, 0.48, 0.485, 0.495, 0.47, 0.515, 0.49, 0.455, 0.51, 0.475, 0.5, 0.475, 0.5, 0.52, 0.5, 0.49, 0.49, 0.495, 0.5, 0.495, 0.485, 0.505, 0.495, 0.465, 0.455, 0.48, 0.475, 0.485, 0.53, 0.495, 0.5, 0.465, 0.515, 0.475, 0.505, 0.505, 0.485, 0.475, 0.49, 0.5, 0.52, 0.48, 0.505, 0.485, 0.515, 0.525, 0.475, 0.47, 0.51, 0.475, 0.45, 0.46, 0.475, 0.485, 0.45, 0.5, 0.515, 0.47, 0.48, 0.46, 0.54, 0.52, 0.47, 0.48, 0.465, 0.51, 0.46, 0.455, 0.485, 0.48, 0.46, 0.46, 0.51, 0.5, 0.495, 0.465, 0.48, 0.465, 0.49, 0.485, 0.47, 0.47, 0.5, 0.48, 0.495, 0.51, 0.495, 0.465, 0.48, 0.48, 0.515, 0.445, 0.52, 0.48, 0.485, 0.51, 0.5, 0.48, 0.505, 0.495, 0.485, 0.49, 0.455, 0.49, 0.5, 0.5, 0.5, 0.545, 0.465, 0.455, 0.52, 0.475, 0.475, 0.485, 0.495, 0.48, 0.46, 0.51, 0.495, 0.465, 0.475, 0.445, 0.49, 0.46, 0.49, 0.51, 0.495, 0.45, 0.475, 0.485, 0.46, 0.44, 0.515, 0.47, 0.465, 0.49, 0.48, 0.44, 0.47, 0.465, 0.45, 0.48, 0.48, 0.49, 0.495, 0.475, 0.505, 0.47, 0.49, 0.465, 0.505, 0.5, 0.525, 0.5, 0.49], finalacc: 0.56, alpha: tensor([0.0504, 0.0471, 0.0458, 0.0510, 0.0462, 0.0478, 0.0468, 0.0458, 0.0478,
        0.0455, 0.0484, 0.0481, 0.0491, 0.0478, 0.0468, 0.0458, 0.0465, 0.0475,
        0.0481, 0.0491, 0.0484])
2022/08/22 11:37:36 -------fail to update alpha------
2022/08/22 11:37:36 The epoch_out: 0, epoch_in: 9 of training alpha finished, alpha: tensor([0.0504, 0.0471, 0.0458, 0.0510, 0.0462, 0.0478, 0.0468, 0.0458, 0.0478,
        0.0455, 0.0484, 0.0481, 0.0491, 0.0478, 0.0468, 0.0458, 0.0465, 0.0475,
        0.0481, 0.0491, 0.0484])
2022/08/22 11:38:04 epoch_out: 1, epoch_in: 0, loss: 0.8061008095741272
2022/08/22 11:38:33 epoch_out: 1, epoch_in: 1, loss: 0.21673809383064507
2022/08/22 11:39:01 epoch_out: 1, epoch_in: 2, loss: 0.11623104559257627
2022/08/22 11:39:29 epoch_out: 1, epoch_in: 3, loss: 0.07645915886387229
2022/08/22 11:39:58 epoch_out: 1, epoch_in: 4, loss: 0.04358686953783035
2022/08/22 11:40:26 epoch_out: 1, epoch_in: 5, loss: 0.01753929709084332
2022/08/22 11:40:55 epoch_out: 1, epoch_in: 6, loss: 0.002543921209871769
2022/08/22 11:41:23 epoch_out: 1, epoch_in: 7, loss: -0.02133283345028758
2022/08/22 11:41:51 epoch_out: 1, epoch_in: 8, loss: -0.05517482329159975
2022/08/22 11:42:19 epoch_out: 1, epoch_in: 9, loss: -0.08764303289353848
2022/08/22 11:42:19 The epoch_out: 1, epoch_in: 9 of training F and G finished, losslist: [0.8061008095741272, 0.21673809383064507, 0.11623104559257627, 0.07645915886387229, 0.04358686953783035, 0.01753929709084332, 0.002543921209871769, -0.02133283345028758, -0.05517482329159975, -0.08764303289353848], acclist: [0, 0.48, 0.485, 0.505, 0.49, 0.52, 0.485, 0.47, 0.49, 0.475, 0.485, 0.48, 0.465, 0.48, 0.445, 0.47, 0.5, 0.475, 0.49, 0.475, 0.47, 0.525, 0.45, 0.5, 0.505, 0.49, 0.485, 0.505, 0.475, 0.49, 0.5, 0.49, 0.51, 0.52, 0.51, 0.51, 0.505, 0.49, 0.475, 0.505, 0.47, 0.495, 0.5, 0.45, 0.5, 0.465, 0.53, 0.5, 0.47, 0.44, 0.485, 0.505, 0.455, 0.525, 0.48, 0.455, 0.51, 0.49, 0.475, 0.47, 0.485, 0.48, 0.495, 0.52, 0.495, 0.52, 0.455, 0.465, 0.45, 0.47, 0.49, 0.49, 0.505, 0.495, 0.48, 0.515, 0.49, 0.49, 0.47, 0.46, 0.48, 0.495, 0.465, 0.47, 0.505, 0.495, 0.455, 0.47, 0.515, 0.47, 0.465, 0.455, 0.46, 0.52, 0.475, 0.515, 0.495, 0.465, 0.435, 0.495, 0.505, 0.43, 0.475, 0.505, 0.47, 0.465, 0.455, 0.49, 0.52, 0.495, 0.475, 0.49, 0.47, 0.475, 0.485, 0.5, 0.495, 0.465, 0.46, 0.47, 0.505, 0.495, 0.475, 0.515, 0.49, 0.465, 0.44, 0.44, 0.5, 0.47, 0.485, 0.465, 0.45, 0.45, 0.455, 0.495, 0.49, 0.5, 0.48, 0.475, 0.48, 0.465, 0.49, 0.475, 0.51, 0.49, 0.465, 0.45, 0.495, 0.455, 0.51, 0.49, 0.47, 0.5, 0.48, 0.46, 0.51, 0.46, 0.5, 0.465, 0.49, 0.475, 0.49, 0.495, 0.485, 0.48, 0.46, 0.44, 0.495, 0.46, 0.49, 0.515, 0.48, 0.49, 0.46, 0.485, 0.495, 0.51, 0.475, 0.47, 0.495, 0.425, 0.445, 0.5, 0.445, 0.415, 0.47, 0.5, 0.455, 0.48, 0.48, 0.465, 0.48, 0.485, 0.495, 0.47, 0.455, 0.475, 0.485, 0.475, 0.515, 0.47, 0.475, 0.485, 0.46, 0.52, 0.515, 0.51, 0.44, 0.46, 0.475, 0.49, 0.455, 0.52, 0.475, 0.48, 0.485, 0.445, 0.455, 0.465, 0.48, 0.45, 0.465, 0.47, 0.465, 0.465, 0.49, 0.505, 0.49, 0.515, 0.5, 0.475, 0.465, 0.515, 0.48, 0.48, 0.47, 0.525, 0.5, 0.43, 0.46, 0.45, 0.5, 0.46, 0.435, 0.49, 0.485, 0.48, 0.455, 0.485, 0.49, 0.455, 0.48, 0.52, 0.5, 0.5, 0.465, 0.49, 0.485, 0.475, 0.485, 0.43, 0.475, 0.49, 0.485, 0.46, 0.485, 0.485, 0.5, 0.515, 0.465, 0.46, 0.51, 0.525, 0.445, 0.48, 0.43, 0.48, 0.465, 0.43, 0.485, 0.445, 0.485, 0.47, 0.49, 0.49, 0.475, 0.49, 0.49, 0.45, 0.5, 0.485, 0.47, 0.48, 0.47, 0.465, 0.44, 0.475, 0.5, 0.455, 0.46, 0.435, 0.49, 0.495, 0.455, 0.465, 0.49, 0.485, 0.48, 0.43, 0.385, 0.455, 0.505, 0.46, 0.435, 0.465, 0.47, 0.475, 0.48, 0.485, 0.475, 0.455, 0.475, 0.495, 0.495, 0.475, 0.455, 0.435, 0.475, 0.475, 0.49, 0.45, 0.5, 0.47, 0.445, 0.48, 0.455, 0.485, 0.465, 0.465, 0.475, 0.495, 0.52, 0.43, 0.485, 0.475, 0.475, 0.455, 0.43, 0.455, 0.465, 0.47, 0.46, 0.455, 0.47, 0.435, 0.47, 0.465, 0.505, 0.46, 0.53, 0.54, 0.505, 0.48, 0.49, 0.515, 0.435, 0.445, 0.51, 0.455, 0.495, 0.485, 0.485, 0.475, 0.44, 0.45, 0.46, 0.45, 0.495, 0.47, 0.46, 0.46, 0.465, 0.44, 0.425, 0.435, 0.435, 0.49, 0.445, 0.49, 0.48, 0.49, 0.46, 0.44, 0.445, 0.465, 0.46, 0.425, 0.46, 0.455, 0.47], finalacc: 0.54, alpha: tensor([0.0504, 0.0471, 0.0458, 0.0510, 0.0462, 0.0478, 0.0468, 0.0458, 0.0478,
        0.0455, 0.0484, 0.0481, 0.0491, 0.0478, 0.0468, 0.0458, 0.0465, 0.0475,
        0.0481, 0.0491, 0.0484])
2022/08/22 11:42:29 -------fail to update alpha------
2022/08/22 11:42:29 The epoch_out: 1, epoch_in: 9 of training alpha finished, alpha: tensor([0.0504, 0.0471, 0.0458, 0.0510, 0.0462, 0.0478, 0.0468, 0.0458, 0.0478,
        0.0455, 0.0484, 0.0481, 0.0491, 0.0478, 0.0468, 0.0458, 0.0465, 0.0475,
        0.0481, 0.0491, 0.0484])
2022/08/22 11:42:57 epoch_out: 2, epoch_in: 0, loss: 0.9190593175590038
2022/08/22 11:43:26 epoch_out: 2, epoch_in: 1, loss: 0.22669730335474014
2022/08/22 11:43:54 epoch_out: 2, epoch_in: 2, loss: 0.11275218725204468
2022/08/22 11:44:22 epoch_out: 2, epoch_in: 3, loss: 0.05315020950511098
2022/08/22 11:44:50 epoch_out: 2, epoch_in: 4, loss: 0.00985287008807063
2022/08/22 11:45:18 epoch_out: 2, epoch_in: 5, loss: -0.027219481486827134
2022/08/22 11:45:46 epoch_out: 2, epoch_in: 6, loss: -0.07001140452921391
2022/08/22 11:46:14 epoch_out: 2, epoch_in: 7, loss: -0.11814752165228129
2022/08/22 11:46:42 epoch_out: 2, epoch_in: 8, loss: -0.1661080704536289
2022/08/22 11:47:11 epoch_out: 2, epoch_in: 9, loss: -0.23537682890892028
2022/08/22 11:47:11 The epoch_out: 2, epoch_in: 9 of training F and G finished, losslist: [0.9190593175590038, 0.22669730335474014, 0.11275218725204468, 0.05315020950511098, 0.00985287008807063, -0.027219481486827134, -0.07001140452921391, -0.11814752165228129, -0.1661080704536289, -0.23537682890892028], acclist: [0, 0.52, 0.52, 0.53, 0.52, 0.485, 0.52, 0.505, 0.5, 0.47, 0.49, 0.505, 0.515, 0.46, 0.515, 0.49, 0.5, 0.51, 0.49, 0.48, 0.52, 0.5, 0.49, 0.465, 0.505, 0.5, 0.485, 0.49, 0.53, 0.495, 0.5, 0.52, 0.49, 0.505, 0.505, 0.47, 0.48, 0.5, 0.49, 0.49, 0.475, 0.45, 0.45, 0.505, 0.5, 0.5, 0.505, 0.44, 0.5, 0.495, 0.52, 0.48, 0.45, 0.505, 0.52, 0.48, 0.505, 0.5, 0.485, 0.545, 0.495, 0.455, 0.5, 0.56, 0.525, 0.515, 0.47, 0.48, 0.51, 0.47, 0.505, 0.52, 0.47, 0.505, 0.505, 0.515, 0.47, 0.48, 0.46, 0.5, 0.5, 0.48, 0.5, 0.53, 0.465, 0.48, 0.47, 0.525, 0.46, 0.515, 0.505, 0.47, 0.5, 0.465, 0.475, 0.52, 0.505, 0.465, 0.47, 0.495, 0.48, 0.475, 0.48, 0.48, 0.465, 0.485, 0.43, 0.495, 0.5, 0.48, 0.495, 0.47, 0.47, 0.495, 0.495, 0.48, 0.46, 0.49, 0.485, 0.48, 0.45, 0.48, 0.455, 0.49, 0.48, 0.49, 0.46, 0.48, 0.48, 0.48, 0.46, 0.495, 0.455, 0.45, 0.445, 0.5, 0.455, 0.46, 0.48, 0.44, 0.44, 0.45, 0.45, 0.505, 0.465, 0.495, 0.45, 0.505, 0.5, 0.49, 0.5, 0.48, 0.485, 0.47, 0.435, 0.46, 0.48, 0.45, 0.48, 0.5, 0.515, 0.435, 0.49, 0.475, 0.495, 0.51, 0.48, 0.47, 0.475, 0.505, 0.46, 0.515, 0.475, 0.455, 0.495, 0.46, 0.46, 0.45, 0.45, 0.435, 0.445, 0.44, 0.48, 0.51, 0.46, 0.485, 0.47, 0.485, 0.46, 0.475, 0.47, 0.475, 0.46, 0.46, 0.445, 0.495, 0.435, 0.48, 0.47, 0.505, 0.5, 0.47, 0.47, 0.445, 0.505, 0.455, 0.465, 0.47, 0.47, 0.465, 0.475, 0.455, 0.47, 0.445, 0.445, 0.44, 0.475, 0.41, 0.46, 0.435, 0.44, 0.455, 0.45, 0.465, 0.425, 0.47, 0.48, 0.435, 0.475, 0.47, 0.465, 0.41, 0.45, 0.46, 0.485, 0.48, 0.43, 0.435, 0.48, 0.47, 0.475, 0.43, 0.46, 0.425, 0.41, 0.455, 0.485, 0.44, 0.445, 0.48, 0.46, 0.46, 0.465, 0.45, 0.46, 0.46, 0.455, 0.455, 0.41, 0.455, 0.43, 0.445, 0.455, 0.485, 0.455, 0.46, 0.46, 0.44, 0.455, 0.425, 0.45, 0.45, 0.44, 0.43, 0.455, 0.435, 0.445, 0.415, 0.395, 0.42, 0.475, 0.45, 0.48, 0.455, 0.455, 0.43, 0.47, 0.44, 0.455, 0.4, 0.445, 0.46, 0.455, 0.44, 0.43, 0.46, 0.455, 0.46, 0.455, 0.45, 0.4, 0.45, 0.455, 0.44, 0.445, 0.4, 0.42, 0.435, 0.43, 0.48, 0.44, 0.415, 0.465, 0.46, 0.465, 0.48, 0.41, 0.415, 0.425, 0.405, 0.425, 0.415, 0.42, 0.44, 0.425, 0.425, 0.43, 0.43, 0.45, 0.42, 0.42, 0.445, 0.445, 0.43, 0.415, 0.445, 0.445, 0.455, 0.435, 0.435, 0.42, 0.43, 0.43, 0.41, 0.425, 0.405, 0.42, 0.435, 0.44, 0.445, 0.425, 0.44, 0.455, 0.44, 0.4, 0.405, 0.415, 0.47, 0.44, 0.435, 0.415, 0.42, 0.43, 0.42, 0.43, 0.45, 0.455, 0.44, 0.41, 0.425, 0.42, 0.435, 0.44, 0.41, 0.42, 0.45, 0.415, 0.435, 0.41, 0.45, 0.405, 0.44, 0.455, 0.455, 0.45, 0.41, 0.435, 0.41, 0.425, 0.445, 0.41, 0.43, 0.415, 0.45, 0.46, 0.445, 0.435, 0.44, 0.445, 0.435, 0.44], finalacc: 0.56, alpha: tensor([0.0504, 0.0471, 0.0458, 0.0510, 0.0462, 0.0478, 0.0468, 0.0458, 0.0478,
        0.0455, 0.0484, 0.0481, 0.0491, 0.0478, 0.0468, 0.0458, 0.0465, 0.0475,
        0.0481, 0.0491, 0.0484])
2022/08/22 11:47:20 -------fail to update alpha------
2022/08/22 11:47:20 The epoch_out: 2, epoch_in: 9 of training alpha finished, alpha: tensor([0.0504, 0.0471, 0.0458, 0.0510, 0.0462, 0.0478, 0.0468, 0.0458, 0.0478,
        0.0455, 0.0484, 0.0481, 0.0491, 0.0478, 0.0468, 0.0458, 0.0465, 0.0475,
        0.0481, 0.0491, 0.0484])
2022/08/22 11:47:48 epoch_out: 3, epoch_in: 0, loss: 1.0259460151195525
2022/08/22 11:48:16 epoch_out: 3, epoch_in: 1, loss: 0.3212133299559355
2022/08/22 11:48:45 epoch_out: 3, epoch_in: 2, loss: 0.19415518511086702
2022/08/22 11:49:13 epoch_out: 3, epoch_in: 3, loss: 0.11756266932934523
2022/08/22 11:49:39 epoch_out: 3, epoch_in: 4, loss: 0.07126321513205766
2022/08/22 11:50:05 epoch_out: 3, epoch_in: 5, loss: 0.005130825191736221
2022/08/22 11:50:31 epoch_out: 3, epoch_in: 6, loss: -0.031908183638006446
2022/08/22 11:50:57 epoch_out: 3, epoch_in: 7, loss: -0.07869262546300888
2022/08/22 11:51:24 epoch_out: 3, epoch_in: 8, loss: -0.1143910875543952
2022/08/22 11:51:51 epoch_out: 3, epoch_in: 9, loss: -0.13182850629091264
2022/08/22 11:51:51 The epoch_out: 3, epoch_in: 9 of training F and G finished, losslist: [1.0259460151195525, 0.3212133299559355, 0.19415518511086702, 0.11756266932934523, 0.07126321513205766, 0.005130825191736221, -0.031908183638006446, -0.07869262546300888, -0.1143910875543952, -0.13182850629091264], acclist: [0, 0.44, 0.44, 0.42, 0.44, 0.42, 0.48, 0.475, 0.485, 0.44, 0.465, 0.44, 0.46, 0.46, 0.48, 0.47, 0.46, 0.495, 0.445, 0.5, 0.5, 0.47, 0.445, 0.43, 0.475, 0.46, 0.455, 0.51, 0.45, 0.45, 0.47, 0.46, 0.445, 0.48, 0.485, 0.44, 0.475, 0.505, 0.47, 0.49, 0.455, 0.46, 0.45, 0.445, 0.47, 0.465, 0.46, 0.475, 0.465, 0.385, 0.475, 0.45, 0.43, 0.47, 0.465, 0.44, 0.48, 0.415, 0.48, 0.505, 0.46, 0.455, 0.465, 0.49, 0.48, 0.455, 0.5, 0.48, 0.49, 0.46, 0.45, 0.45, 0.415, 0.455, 0.495, 0.455, 0.47, 0.465, 0.495, 0.455, 0.405, 0.475, 0.475, 0.475, 0.455, 0.475, 0.46, 0.48, 0.505, 0.435, 0.435, 0.46, 0.435, 0.455, 0.46, 0.425, 0.505, 0.425, 0.43, 0.445, 0.455, 0.47, 0.43, 0.435, 0.465, 0.485, 0.395, 0.47, 0.49, 0.43, 0.425, 0.45, 0.46, 0.435, 0.45, 0.4, 0.44, 0.44, 0.455, 0.455, 0.485, 0.44, 0.46, 0.485, 0.405, 0.375, 0.41, 0.42, 0.455, 0.385, 0.46, 0.455, 0.445, 0.465, 0.445, 0.44, 0.44, 0.4, 0.445, 0.44, 0.44, 0.45, 0.42, 0.41, 0.46, 0.455, 0.475, 0.455, 0.385, 0.44, 0.47, 0.465, 0.45, 0.47, 0.435, 0.44, 0.415, 0.445, 0.445, 0.43, 0.47, 0.46, 0.435, 0.435, 0.435, 0.415, 0.43, 0.425, 0.42, 0.44, 0.475, 0.455, 0.46, 0.45, 0.47, 0.465, 0.43, 0.435, 0.425, 0.41, 0.45, 0.415, 0.45, 0.41, 0.445, 0.445, 0.45, 0.405, 0.42, 0.44, 0.47, 0.46, 0.44, 0.415, 0.425, 0.41, 0.41, 0.43, 0.435, 0.46, 0.44, 0.43, 0.425, 0.415, 0.435, 0.425, 0.41, 0.445, 0.47, 0.47, 0.41, 0.455, 0.43, 0.41, 0.435, 0.425, 0.42, 0.445, 0.42, 0.45, 0.465, 0.435, 0.43, 0.415, 0.43, 0.455, 0.445, 0.415, 0.405, 0.42, 0.43, 0.43, 0.415, 0.45, 0.43, 0.44, 0.465, 0.455, 0.46, 0.415, 0.42, 0.41, 0.47, 0.425, 0.405, 0.45, 0.46, 0.42, 0.47, 0.425, 0.45, 0.445, 0.475, 0.41, 0.465, 0.43, 0.415, 0.47, 0.41, 0.41, 0.425, 0.42, 0.43, 0.46, 0.44, 0.44, 0.405, 0.435, 0.43, 0.395, 0.4, 0.4, 0.455, 0.395, 0.43, 0.405, 0.42, 0.42, 0.43, 0.425, 0.41, 0.425, 0.42, 0.445, 0.42, 0.425, 0.37, 0.42, 0.425, 0.42, 0.46, 0.425, 0.39, 0.405, 0.445, 0.385, 0.4, 0.405, 0.425, 0.365, 0.45, 0.475, 0.41, 0.43, 0.43, 0.42, 0.4, 0.425, 0.425, 0.445, 0.425, 0.43, 0.405, 0.415, 0.395, 0.425, 0.415, 0.425, 0.41, 0.475, 0.41, 0.395, 0.4, 0.4, 0.43, 0.4, 0.415, 0.415, 0.4, 0.435, 0.43, 0.425, 0.415, 0.44, 0.415, 0.425, 0.425, 0.43, 0.44, 0.41, 0.425, 0.41, 0.435, 0.44, 0.415, 0.405, 0.4, 0.44, 0.43, 0.405, 0.415, 0.445, 0.425, 0.425, 0.395, 0.41, 0.44, 0.435, 0.375, 0.425, 0.435, 0.405, 0.41, 0.39, 0.39, 0.415, 0.445, 0.385, 0.43, 0.42, 0.405, 0.395, 0.37, 0.39, 0.385, 0.415, 0.44, 0.405, 0.405, 0.4, 0.43, 0.44, 0.405, 0.43, 0.42, 0.42, 0.415, 0.42, 0.375, 0.375, 0.42, 0.435, 0.405, 0.435, 0.44, 0.45, 0.405, 0.42, 0.47, 0.415, 0.435], finalacc: 0.51, alpha: tensor([0.0504, 0.0471, 0.0458, 0.0510, 0.0462, 0.0478, 0.0468, 0.0458, 0.0478,
        0.0455, 0.0484, 0.0481, 0.0491, 0.0478, 0.0468, 0.0458, 0.0465, 0.0475,
        0.0481, 0.0491, 0.0484])
2022/08/22 11:52:00 -------fail to update alpha------
2022/08/22 11:52:00 The epoch_out: 3, epoch_in: 9 of training alpha finished, alpha: tensor([0.0504, 0.0471, 0.0458, 0.0510, 0.0462, 0.0478, 0.0468, 0.0458, 0.0478,
        0.0455, 0.0484, 0.0481, 0.0491, 0.0478, 0.0468, 0.0458, 0.0465, 0.0475,
        0.0481, 0.0491, 0.0484])
2022/08/22 11:52:27 epoch_out: 4, epoch_in: 0, loss: 0.7408011764287948
2022/08/22 11:52:54 epoch_out: 4, epoch_in: 1, loss: 0.1945474434643984
2022/08/22 11:53:20 epoch_out: 4, epoch_in: 2, loss: 0.10095123723149299
2022/08/22 11:53:47 epoch_out: 4, epoch_in: 3, loss: 0.03065149849280715
2022/08/22 11:54:14 epoch_out: 4, epoch_in: 4, loss: 0.005187924113124609
2022/08/22 11:54:41 epoch_out: 4, epoch_in: 5, loss: -0.030524836014956237
2022/08/22 11:55:07 epoch_out: 4, epoch_in: 6, loss: -0.0990641912445426
2022/08/22 11:55:34 epoch_out: 4, epoch_in: 7, loss: -0.11472607031464577
2022/08/22 11:56:01 epoch_out: 4, epoch_in: 8, loss: -0.1513643428683281
2022/08/22 11:56:28 epoch_out: 4, epoch_in: 9, loss: -0.2136999111622572
2022/08/22 11:56:28 The epoch_out: 4, epoch_in: 9 of training F and G finished, losslist: [0.7408011764287948, 0.1945474434643984, 0.10095123723149299, 0.03065149849280715, 0.005187924113124609, -0.030524836014956237, -0.0990641912445426, -0.11472607031464577, -0.1513643428683281, -0.2136999111622572], acclist: [0, 0.45, 0.46, 0.515, 0.51, 0.52, 0.52, 0.485, 0.515, 0.535, 0.52, 0.525, 0.525, 0.5, 0.505, 0.53, 0.48, 0.535, 0.505, 0.52, 0.48, 0.545, 0.52, 0.535, 0.56, 0.525, 0.555, 0.53, 0.505, 0.5, 0.505, 0.5, 0.49, 0.5, 0.475, 0.505, 0.475, 0.48, 0.5, 0.515, 0.5, 0.505, 0.5, 0.535, 0.51, 0.55, 0.55, 0.545, 0.505, 0.515, 0.5, 0.51, 0.49, 0.475, 0.51, 0.535, 0.505, 0.53, 0.46, 0.49, 0.525, 0.525, 0.485, 0.515, 0.495, 0.55, 0.515, 0.525, 0.5, 0.53, 0.51, 0.495, 0.52, 0.505, 0.525, 0.51, 0.52, 0.445, 0.46, 0.5, 0.51, 0.505, 0.5, 0.51, 0.525, 0.47, 0.555, 0.495, 0.525, 0.505, 0.505, 0.465, 0.465, 0.505, 0.505, 0.49, 0.515, 0.53, 0.505, 0.515, 0.565, 0.545, 0.535, 0.5, 0.505, 0.52, 0.5, 0.505, 0.52, 0.49, 0.475, 0.495, 0.51, 0.485, 0.5, 0.53, 0.495, 0.485, 0.53, 0.53, 0.54, 0.505, 0.5, 0.53, 0.505, 0.46, 0.485, 0.515, 0.51, 0.53, 0.515, 0.47, 0.505, 0.515, 0.515, 0.5, 0.51, 0.515, 0.53, 0.49, 0.49, 0.49, 0.55, 0.565, 0.52, 0.505, 0.51, 0.525, 0.525, 0.505, 0.495, 0.515, 0.5, 0.475, 0.5, 0.505, 0.47, 0.53, 0.505, 0.52, 0.525, 0.51, 0.515, 0.475, 0.505, 0.505, 0.465, 0.49, 0.52, 0.48, 0.53, 0.505, 0.52, 0.5, 0.47, 0.485, 0.495, 0.495, 0.505, 0.525, 0.52, 0.52, 0.52, 0.54, 0.49, 0.485, 0.52, 0.525, 0.495, 0.495, 0.52, 0.51, 0.535, 0.495, 0.52, 0.475, 0.475, 0.515, 0.49, 0.475, 0.54, 0.49, 0.51, 0.53, 0.515, 0.49, 0.55, 0.47, 0.515, 0.475, 0.47, 0.485, 0.46, 0.48, 0.485, 0.505, 0.53, 0.48, 0.54, 0.535, 0.525, 0.505, 0.525, 0.5, 0.505, 0.51, 0.455, 0.51, 0.48, 0.49, 0.475, 0.49, 0.51, 0.45, 0.475, 0.49, 0.505, 0.495, 0.46, 0.515, 0.5, 0.49, 0.5, 0.475, 0.495, 0.465, 0.47, 0.505, 0.48, 0.485, 0.455, 0.49, 0.49, 0.535, 0.51, 0.48, 0.51, 0.5, 0.48, 0.495, 0.445, 0.5, 0.5, 0.485, 0.49, 0.44, 0.51, 0.5, 0.485, 0.495, 0.47, 0.495, 0.495, 0.495, 0.48, 0.485, 0.515, 0.49, 0.5, 0.45, 0.51, 0.46, 0.49, 0.485, 0.51, 0.49, 0.49, 0.52, 0.46, 0.49, 0.475, 0.46, 0.51, 0.49, 0.47, 0.48, 0.5, 0.515, 0.48, 0.485, 0.47, 0.495, 0.505, 0.515, 0.495, 0.495, 0.525, 0.495, 0.49, 0.485, 0.49, 0.445, 0.485, 0.475, 0.54, 0.49, 0.44, 0.5, 0.475, 0.5, 0.49, 0.465, 0.455, 0.5, 0.485, 0.455, 0.51, 0.49, 0.47, 0.48, 0.485, 0.49, 0.495, 0.485, 0.47, 0.505, 0.47, 0.475, 0.465, 0.495, 0.51, 0.515, 0.5, 0.49, 0.45, 0.51, 0.515, 0.465, 0.445, 0.5, 0.51, 0.52, 0.505, 0.47, 0.445, 0.48, 0.465, 0.455, 0.48, 0.48, 0.5, 0.47, 0.47, 0.525, 0.495, 0.47, 0.49, 0.455, 0.455, 0.46, 0.475, 0.48, 0.465, 0.53, 0.52, 0.46, 0.49, 0.47, 0.485, 0.5, 0.525, 0.485, 0.475, 0.505, 0.465, 0.505, 0.485, 0.495, 0.525, 0.475, 0.46, 0.495, 0.46, 0.495, 0.495, 0.46, 0.48, 0.47, 0.495, 0.475, 0.485], finalacc: 0.565, alpha: tensor([0.0504, 0.0471, 0.0458, 0.0510, 0.0462, 0.0478, 0.0468, 0.0458, 0.0478,
        0.0455, 0.0484, 0.0481, 0.0491, 0.0478, 0.0468, 0.0458, 0.0465, 0.0475,
        0.0481, 0.0491, 0.0484])
2022/08/22 11:56:37 -------fail to update alpha------
2022/08/22 11:56:37 The epoch_out: 4, epoch_in: 9 of training alpha finished, alpha: tensor([0.0504, 0.0471, 0.0458, 0.0510, 0.0462, 0.0478, 0.0468, 0.0458, 0.0478,
        0.0455, 0.0484, 0.0481, 0.0491, 0.0478, 0.0468, 0.0458, 0.0465, 0.0475,
        0.0481, 0.0491, 0.0484])
2022/08/22 11:57:04 epoch_out: 5, epoch_in: 0, loss: 0.707913252338767
2022/08/22 11:57:30 epoch_out: 5, epoch_in: 1, loss: 0.13727168682962657
2022/08/22 11:57:57 epoch_out: 5, epoch_in: 2, loss: 0.06525495806708932
2022/08/22 11:58:24 epoch_out: 5, epoch_in: 3, loss: 0.033252956345677376
2022/08/22 11:58:50 epoch_out: 5, epoch_in: 4, loss: -0.007157998206093907
2022/08/22 11:59:17 epoch_out: 5, epoch_in: 5, loss: -0.05100607881322503
2022/08/22 11:59:44 epoch_out: 5, epoch_in: 6, loss: -0.0823459168896079
2022/08/22 12:00:11 epoch_out: 5, epoch_in: 7, loss: -0.09094038167968392
2022/08/22 12:00:37 epoch_out: 5, epoch_in: 8, loss: -0.14325089734047652
2022/08/22 12:01:04 epoch_out: 5, epoch_in: 9, loss: -0.1749058820307255
2022/08/22 12:01:04 The epoch_out: 5, epoch_in: 9 of training F and G finished, losslist: [0.707913252338767, 0.13727168682962657, 0.06525495806708932, 0.033252956345677376, -0.007157998206093907, -0.05100607881322503, -0.0823459168896079, -0.09094038167968392, -0.14325089734047652, -0.1749058820307255], acclist: [0, 0.505, 0.53, 0.515, 0.53, 0.525, 0.515, 0.515, 0.52, 0.515, 0.455, 0.495, 0.535, 0.52, 0.53, 0.54, 0.495, 0.515, 0.52, 0.505, 0.515, 0.525, 0.495, 0.51, 0.48, 0.46, 0.515, 0.5, 0.455, 0.5, 0.49, 0.52, 0.51, 0.5, 0.475, 0.495, 0.505, 0.485, 0.48, 0.48, 0.495, 0.525, 0.475, 0.5, 0.515, 0.5, 0.48, 0.5, 0.525, 0.51, 0.515, 0.52, 0.495, 0.545, 0.52, 0.47, 0.51, 0.5, 0.55, 0.51, 0.505, 0.49, 0.485, 0.495, 0.555, 0.535, 0.52, 0.535, 0.51, 0.51, 0.45, 0.525, 0.52, 0.53, 0.53, 0.525, 0.525, 0.525, 0.54, 0.52, 0.51, 0.525, 0.535, 0.495, 0.51, 0.46, 0.515, 0.525, 0.48, 0.495, 0.515, 0.53, 0.515, 0.515, 0.465, 0.565, 0.535, 0.495, 0.515, 0.51, 0.53, 0.5, 0.54, 0.51, 0.515, 0.475, 0.495, 0.5, 0.475, 0.495, 0.525, 0.48, 0.505, 0.515, 0.5, 0.465, 0.495, 0.51, 0.475, 0.5, 0.5, 0.51, 0.505, 0.48, 0.505, 0.5, 0.49, 0.535, 0.495, 0.49, 0.49, 0.48, 0.53, 0.505, 0.515, 0.495, 0.445, 0.445, 0.52, 0.535, 0.53, 0.45, 0.445, 0.495, 0.495, 0.48, 0.43, 0.495, 0.5, 0.48, 0.515, 0.48, 0.47, 0.51, 0.515, 0.47, 0.495, 0.505, 0.51, 0.52, 0.5, 0.49, 0.48, 0.455, 0.49, 0.48, 0.49, 0.485, 0.52, 0.495, 0.495, 0.48, 0.515, 0.49, 0.475, 0.54, 0.46, 0.47, 0.5, 0.485, 0.49, 0.5, 0.505, 0.495, 0.49, 0.47, 0.5, 0.48, 0.49, 0.505, 0.515, 0.485, 0.515, 0.505, 0.455, 0.455, 0.475, 0.545, 0.45, 0.48, 0.505, 0.495, 0.49, 0.465, 0.53, 0.485, 0.49, 0.46, 0.515, 0.49, 0.495, 0.475, 0.5, 0.49, 0.465, 0.49, 0.48, 0.47, 0.455, 0.44, 0.52, 0.49, 0.53, 0.475, 0.485, 0.5, 0.485, 0.5, 0.48, 0.495, 0.525, 0.525, 0.53, 0.48, 0.495, 0.49, 0.47, 0.525, 0.475, 0.475, 0.47, 0.485, 0.48, 0.49, 0.485, 0.47, 0.465, 0.455, 0.46, 0.495, 0.505, 0.52, 0.485, 0.51, 0.47, 0.465, 0.485, 0.46, 0.46, 0.47, 0.45, 0.495, 0.5, 0.455, 0.49, 0.515, 0.47, 0.45, 0.46, 0.475, 0.445, 0.485, 0.455, 0.505, 0.46, 0.465, 0.46, 0.475, 0.47, 0.485, 0.47, 0.465, 0.48, 0.465, 0.44, 0.5, 0.46, 0.48, 0.48, 0.51, 0.5, 0.45, 0.49, 0.495, 0.495, 0.505, 0.45, 0.48, 0.47, 0.51, 0.475, 0.48, 0.445, 0.455, 0.47, 0.5, 0.48, 0.465, 0.46, 0.505, 0.47, 0.465, 0.5, 0.47, 0.48, 0.49, 0.515, 0.47, 0.515, 0.47, 0.505, 0.495, 0.465, 0.47, 0.485, 0.46, 0.46, 0.425, 0.46, 0.49, 0.49, 0.47, 0.45, 0.48, 0.475, 0.48, 0.465, 0.53, 0.485, 0.495, 0.46, 0.45, 0.48, 0.49, 0.45, 0.505, 0.515, 0.465, 0.445, 0.48, 0.485, 0.485, 0.465, 0.48, 0.49, 0.5, 0.48, 0.485, 0.485, 0.475, 0.475, 0.475, 0.465, 0.475, 0.45, 0.465, 0.48, 0.475, 0.47, 0.46, 0.455, 0.5, 0.48, 0.465, 0.505, 0.455, 0.46, 0.445, 0.47, 0.46, 0.485, 0.455, 0.46, 0.455, 0.44, 0.48, 0.5, 0.49, 0.5, 0.49, 0.49, 0.495, 0.465, 0.475, 0.475, 0.48, 0.445, 0.47, 0.48, 0.475, 0.485], finalacc: 0.565, alpha: tensor([0.0504, 0.0471, 0.0458, 0.0510, 0.0462, 0.0478, 0.0468, 0.0458, 0.0478,
        0.0455, 0.0484, 0.0481, 0.0491, 0.0478, 0.0468, 0.0458, 0.0465, 0.0475,
        0.0481, 0.0491, 0.0484])
2022/08/22 12:01:13 -------fail to update alpha------
2022/08/22 12:01:13 The epoch_out: 5, epoch_in: 9 of training alpha finished, alpha: tensor([0.0504, 0.0471, 0.0458, 0.0510, 0.0462, 0.0478, 0.0468, 0.0458, 0.0478,
        0.0455, 0.0484, 0.0481, 0.0491, 0.0478, 0.0468, 0.0458, 0.0465, 0.0475,
        0.0481, 0.0491, 0.0484])
2022/08/22 12:01:40 epoch_out: 6, epoch_in: 0, loss: 0.961518382281065
2022/08/22 12:02:07 epoch_out: 6, epoch_in: 1, loss: 0.32873774766922
2022/08/22 12:02:34 epoch_out: 6, epoch_in: 2, loss: 0.18094383254647256
2022/08/22 12:03:01 epoch_out: 6, epoch_in: 3, loss: 0.09928554426878691
2022/08/22 12:03:27 epoch_out: 6, epoch_in: 4, loss: 0.0677130519412458
2022/08/22 12:03:54 epoch_out: 6, epoch_in: 5, loss: 0.016103882249444722
2022/08/22 12:04:21 epoch_out: 6, epoch_in: 6, loss: -0.00642750570550561
2022/08/22 12:04:48 epoch_out: 6, epoch_in: 7, loss: -0.03327768966555596
2022/08/22 12:05:14 epoch_out: 6, epoch_in: 8, loss: -0.07354324003681541
2022/08/22 12:05:41 epoch_out: 6, epoch_in: 9, loss: -0.08807894699275494
2022/08/22 12:05:41 The epoch_out: 6, epoch_in: 9 of training F and G finished, losslist: [0.961518382281065, 0.32873774766922, 0.18094383254647256, 0.09928554426878691, 0.0677130519412458, 0.016103882249444722, -0.00642750570550561, -0.03327768966555596, -0.07354324003681541, -0.08807894699275494], acclist: [0, 0.49, 0.485, 0.45, 0.47, 0.485, 0.47, 0.52, 0.495, 0.535, 0.5, 0.5, 0.52, 0.52, 0.51, 0.5, 0.515, 0.47, 0.48, 0.49, 0.485, 0.51, 0.505, 0.5, 0.51, 0.485, 0.535, 0.455, 0.49, 0.52, 0.49, 0.525, 0.45, 0.525, 0.495, 0.495, 0.505, 0.505, 0.545, 0.505, 0.45, 0.495, 0.47, 0.515, 0.465, 0.46, 0.525, 0.465, 0.52, 0.51, 0.505, 0.49, 0.5, 0.495, 0.505, 0.5, 0.525, 0.495, 0.49, 0.505, 0.495, 0.505, 0.49, 0.505, 0.5, 0.465, 0.51, 0.5, 0.51, 0.5, 0.535, 0.46, 0.51, 0.465, 0.5, 0.52, 0.5, 0.455, 0.48, 0.505, 0.49, 0.525, 0.5, 0.525, 0.475, 0.475, 0.515, 0.46, 0.475, 0.48, 0.465, 0.51, 0.475, 0.49, 0.485, 0.505, 0.51, 0.51, 0.485, 0.505, 0.505, 0.495, 0.44, 0.49, 0.505, 0.505, 0.48, 0.51, 0.53, 0.47, 0.5, 0.45, 0.5, 0.505, 0.525, 0.485, 0.51, 0.52, 0.485, 0.48, 0.455, 0.475, 0.5, 0.485, 0.49, 0.53, 0.535, 0.445, 0.475, 0.485, 0.515, 0.495, 0.495, 0.51, 0.485, 0.5, 0.485, 0.495, 0.485, 0.485, 0.51, 0.46, 0.49, 0.495, 0.455, 0.475, 0.505, 0.475, 0.48, 0.475, 0.47, 0.485, 0.485, 0.45, 0.45, 0.48, 0.485, 0.435, 0.5, 0.425, 0.455, 0.49, 0.47, 0.455, 0.47, 0.475, 0.455, 0.49, 0.46, 0.465, 0.52, 0.485, 0.435, 0.475, 0.45, 0.49, 0.525, 0.49, 0.47, 0.525, 0.52, 0.445, 0.49, 0.46, 0.53, 0.51, 0.485, 0.505, 0.485, 0.47, 0.46, 0.455, 0.495, 0.48, 0.46, 0.455, 0.47, 0.475, 0.505, 0.475, 0.47, 0.485, 0.46, 0.47, 0.465, 0.455, 0.495, 0.5, 0.485, 0.46, 0.455, 0.435, 0.455, 0.445, 0.495, 0.475, 0.46, 0.435, 0.455, 0.465, 0.49, 0.48, 0.455, 0.475, 0.495, 0.475, 0.43, 0.455, 0.5, 0.49, 0.46, 0.5, 0.465, 0.48, 0.5, 0.48, 0.455, 0.45, 0.5, 0.47, 0.465, 0.46, 0.475, 0.48, 0.51, 0.46, 0.475, 0.465, 0.475, 0.46, 0.45, 0.475, 0.43, 0.46, 0.475, 0.43, 0.455, 0.48, 0.485, 0.47, 0.465, 0.48, 0.45, 0.44, 0.465, 0.42, 0.505, 0.46, 0.475, 0.435, 0.445, 0.45, 0.445, 0.435, 0.46, 0.465, 0.475, 0.45, 0.455, 0.49, 0.45, 0.46, 0.49, 0.495, 0.47, 0.48, 0.465, 0.47, 0.445, 0.45, 0.475, 0.48, 0.46, 0.47, 0.465, 0.445, 0.435, 0.445, 0.45, 0.455, 0.46, 0.475, 0.43, 0.44, 0.47, 0.455, 0.44, 0.475, 0.47, 0.46, 0.455, 0.44, 0.455, 0.465, 0.46, 0.455, 0.42, 0.465, 0.425, 0.455, 0.48, 0.47, 0.41, 0.495, 0.44, 0.475, 0.46, 0.445, 0.43, 0.445, 0.47, 0.485, 0.44, 0.42, 0.465, 0.465, 0.44, 0.425, 0.45, 0.435, 0.455, 0.435, 0.44, 0.475, 0.43, 0.465, 0.48, 0.48, 0.425, 0.475, 0.435, 0.44, 0.445, 0.475, 0.47, 0.48, 0.47, 0.42, 0.45, 0.45, 0.45, 0.45, 0.435, 0.48, 0.46, 0.445, 0.44, 0.465, 0.405, 0.45, 0.435, 0.46, 0.445, 0.46, 0.45, 0.44, 0.485, 0.425, 0.44, 0.445, 0.45, 0.415, 0.47, 0.435, 0.465, 0.42, 0.455, 0.455, 0.475, 0.45, 0.48, 0.445, 0.455, 0.45, 0.46, 0.475, 0.46, 0.435, 0.455, 0.45, 0.425], finalacc: 0.545, alpha: tensor([0.0504, 0.0471, 0.0458, 0.0510, 0.0462, 0.0478, 0.0468, 0.0458, 0.0478,
        0.0455, 0.0484, 0.0481, 0.0491, 0.0478, 0.0468, 0.0458, 0.0465, 0.0475,
        0.0481, 0.0491, 0.0484])
2022/08/22 12:05:50 -------fail to update alpha------
2022/08/22 12:05:50 The epoch_out: 6, epoch_in: 9 of training alpha finished, alpha: tensor([0.0504, 0.0471, 0.0458, 0.0510, 0.0462, 0.0478, 0.0468, 0.0458, 0.0478,
        0.0455, 0.0484, 0.0481, 0.0491, 0.0478, 0.0468, 0.0458, 0.0465, 0.0475,
        0.0481, 0.0491, 0.0484])
2022/08/22 12:06:17 epoch_out: 7, epoch_in: 0, loss: 1.8708209946751595
2022/08/22 12:06:44 epoch_out: 7, epoch_in: 1, loss: 0.624567075073719
2022/08/22 12:07:11 epoch_out: 7, epoch_in: 2, loss: 0.389664213731885
2022/08/22 12:07:38 epoch_out: 7, epoch_in: 3, loss: 0.2737072169780731
2022/08/22 12:08:04 epoch_out: 7, epoch_in: 4, loss: 0.1840549498796463
2022/08/22 12:08:31 epoch_out: 7, epoch_in: 5, loss: 0.12180120944976806
2022/08/22 12:08:58 epoch_out: 7, epoch_in: 6, loss: 0.11055613067001105
2022/08/22 12:09:23 epoch_out: 7, epoch_in: 7, loss: 0.05924739558249712
2022/08/22 12:09:49 epoch_out: 7, epoch_in: 8, loss: 0.03955985950306058
2022/08/22 12:10:14 epoch_out: 7, epoch_in: 9, loss: 0.0009279238991439342
2022/08/22 12:10:14 The epoch_out: 7, epoch_in: 9 of training F and G finished, losslist: [1.8708209946751595, 0.624567075073719, 0.389664213731885, 0.2737072169780731, 0.1840549498796463, 0.12180120944976806, 0.11055613067001105, 0.05924739558249712, 0.03955985950306058, 0.0009279238991439342], acclist: [0, 0.455, 0.555, 0.52, 0.52, 0.495, 0.555, 0.505, 0.555, 0.49, 0.495, 0.545, 0.505, 0.565, 0.51, 0.53, 0.52, 0.52, 0.49, 0.535, 0.51, 0.48, 0.52, 0.53, 0.52, 0.51, 0.535, 0.52, 0.54, 0.49, 0.545, 0.535, 0.51, 0.495, 0.505, 0.515, 0.505, 0.515, 0.54, 0.46, 0.5, 0.495, 0.475, 0.52, 0.505, 0.54, 0.575, 0.51, 0.495, 0.55, 0.515, 0.52, 0.51, 0.535, 0.485, 0.51, 0.53, 0.5, 0.515, 0.505, 0.55, 0.52, 0.495, 0.51, 0.475, 0.515, 0.565, 0.505, 0.51, 0.54, 0.505, 0.56, 0.48, 0.51, 0.485, 0.515, 0.48, 0.51, 0.52, 0.54, 0.54, 0.53, 0.53, 0.52, 0.51, 0.56, 0.48, 0.475, 0.515, 0.495, 0.53, 0.495, 0.52, 0.495, 0.475, 0.515, 0.57, 0.525, 0.55, 0.51, 0.505, 0.525, 0.5, 0.505, 0.49, 0.475, 0.505, 0.495, 0.52, 0.495, 0.52, 0.5, 0.54, 0.54, 0.48, 0.53, 0.515, 0.49, 0.505, 0.505, 0.5, 0.53, 0.52, 0.47, 0.55, 0.545, 0.5, 0.505, 0.52, 0.49, 0.505, 0.48, 0.525, 0.52, 0.525, 0.505, 0.485, 0.52, 0.495, 0.51, 0.505, 0.515, 0.515, 0.49, 0.5, 0.5, 0.49, 0.495, 0.49, 0.47, 0.52, 0.515, 0.52, 0.505, 0.545, 0.515, 0.485, 0.5, 0.505, 0.535, 0.51, 0.505, 0.49, 0.53, 0.53, 0.505, 0.505, 0.535, 0.505, 0.505, 0.49, 0.515, 0.53, 0.5, 0.49, 0.5, 0.515, 0.48, 0.51, 0.53, 0.505, 0.48, 0.495, 0.505, 0.51, 0.46, 0.515, 0.495, 0.505, 0.49, 0.56, 0.5, 0.47, 0.525, 0.49, 0.51, 0.525, 0.46, 0.51, 0.485, 0.515, 0.47, 0.495, 0.47, 0.52, 0.495, 0.53, 0.5, 0.515, 0.485, 0.475, 0.5, 0.495, 0.475, 0.465, 0.475, 0.53, 0.495, 0.495, 0.495, 0.47, 0.505, 0.52, 0.5, 0.5, 0.51, 0.48, 0.52, 0.49, 0.545, 0.5, 0.475, 0.495, 0.49, 0.48, 0.51, 0.495, 0.475, 0.505, 0.485, 0.46, 0.5, 0.505, 0.485, 0.485, 0.475, 0.48, 0.52, 0.48, 0.49, 0.53, 0.485, 0.535, 0.505, 0.51, 0.505, 0.515, 0.51, 0.49, 0.465, 0.52, 0.495, 0.54, 0.515, 0.5, 0.49, 0.485, 0.46, 0.48, 0.47, 0.51, 0.485, 0.515, 0.535, 0.49, 0.465, 0.49, 0.56, 0.535, 0.53, 0.51, 0.48, 0.48, 0.53, 0.495, 0.545, 0.48, 0.49, 0.525, 0.485, 0.46, 0.45, 0.485, 0.51, 0.485, 0.485, 0.52, 0.475, 0.49, 0.5, 0.49, 0.495, 0.5, 0.48, 0.48, 0.495, 0.48, 0.46, 0.465, 0.49, 0.485, 0.495, 0.525, 0.5, 0.49, 0.475, 0.46, 0.5, 0.515, 0.495, 0.495, 0.515, 0.47, 0.5, 0.505, 0.485, 0.44, 0.435, 0.48, 0.525, 0.495, 0.48, 0.46, 0.5, 0.49, 0.495, 0.505, 0.465, 0.48, 0.475, 0.52, 0.52, 0.49, 0.485, 0.515, 0.475, 0.475, 0.52, 0.495, 0.5, 0.465, 0.49, 0.495, 0.5, 0.485, 0.495, 0.49, 0.49, 0.525, 0.5, 0.51, 0.47, 0.505, 0.44, 0.47, 0.47, 0.5, 0.465, 0.49, 0.475, 0.495, 0.465, 0.495, 0.49, 0.475, 0.495, 0.5, 0.515, 0.46, 0.465, 0.495, 0.51, 0.485, 0.515, 0.475, 0.505, 0.49, 0.49, 0.465, 0.505, 0.465, 0.47, 0.505, 0.445, 0.435, 0.49, 0.475, 0.465, 0.47, 0.465, 0.475], finalacc: 0.575, alpha: tensor([0.0504, 0.0471, 0.0458, 0.0510, 0.0462, 0.0478, 0.0468, 0.0458, 0.0478,
        0.0455, 0.0484, 0.0481, 0.0491, 0.0478, 0.0468, 0.0458, 0.0465, 0.0475,
        0.0481, 0.0491, 0.0484])
2022/08/22 12:10:22 -------fail to update alpha------
2022/08/22 12:10:22 The epoch_out: 7, epoch_in: 9 of training alpha finished, alpha: tensor([0.0504, 0.0471, 0.0458, 0.0510, 0.0462, 0.0478, 0.0468, 0.0458, 0.0478,
        0.0455, 0.0484, 0.0481, 0.0491, 0.0478, 0.0468, 0.0458, 0.0465, 0.0475,
        0.0481, 0.0491, 0.0484])
2022/08/22 12:10:47 epoch_out: 8, epoch_in: 0, loss: 0.4625922400504351
2022/08/22 12:11:12 epoch_out: 8, epoch_in: 1, loss: 0.09602150358259678
2022/08/22 12:11:36 epoch_out: 8, epoch_in: 2, loss: 0.03516243579797447
