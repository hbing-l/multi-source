2022/08/30 22:28:32 available device: cuda:0
2022/08/30 22:28:48 epoch_out: 0, epoch_in: 0, loss: 0.9793350465595723
2022/08/30 22:29:00 epoch_out: 0, epoch_in: 1, loss: 0.025174788385629653
2022/08/30 22:29:11 epoch_out: 0, epoch_in: 2, loss: -0.45772619135677817
2022/08/30 22:29:22 epoch_out: 0, epoch_in: 3, loss: -0.6545410457998514
2022/08/30 22:29:34 epoch_out: 0, epoch_in: 4, loss: -0.946132718399167
2022/08/30 22:29:46 epoch_out: 0, epoch_in: 5, loss: -1.184416389837861
2022/08/30 22:29:57 epoch_out: 0, epoch_in: 6, loss: -1.615241640806198
2022/08/30 22:30:09 epoch_out: 0, epoch_in: 7, loss: -2.0117378756403923
2022/08/30 22:30:21 epoch_out: 0, epoch_in: 8, loss: -2.301046499609947
2022/08/30 22:30:32 epoch_out: 0, epoch_in: 9, loss: -2.5614446252584457
2022/08/30 22:30:32 The epoch_out: 0, epoch_in: 9 of training F and G finished, losslist: [0.9793350465595723, 0.025174788385629653, -0.45772619135677817, -0.6545410457998514, -0.946132718399167, -1.184416389837861, -1.615241640806198, -2.0117378756403923, -2.301046499609947, -2.5614446252584457], acclist: [0, 0.44, 0.445, 0.49, 0.5, 0.49, 0.49, 0.535, 0.5, 0.495, 0.48, 0.46, 0.465, 0.48, 0.505, 0.495, 0.505, 0.485, 0.5, 0.46, 0.455, 0.47, 0.48, 0.495, 0.525, 0.51, 0.505, 0.46, 0.475, 0.51, 0.485, 0.525, 0.515, 0.47, 0.48, 0.5, 0.515, 0.44, 0.465, 0.5, 0.51, 0.505, 0.48, 0.48, 0.48, 0.46, 0.485, 0.5, 0.485, 0.515, 0.505, 0.48, 0.51, 0.475, 0.445, 0.48, 0.485, 0.515, 0.5, 0.48, 0.485, 0.475, 0.475, 0.48, 0.5, 0.505, 0.49, 0.51, 0.49, 0.45, 0.455, 0.46, 0.54, 0.535, 0.49, 0.475, 0.44, 0.495, 0.51, 0.505, 0.48, 0.505, 0.5, 0.47, 0.52, 0.435, 0.495, 0.465, 0.46, 0.47, 0.46, 0.485, 0.49, 0.48, 0.47, 0.49, 0.495, 0.46, 0.51, 0.46, 0.45, 0.48, 0.49, 0.49, 0.48, 0.485, 0.465, 0.465, 0.455, 0.47, 0.465, 0.47, 0.435, 0.47, 0.475, 0.495, 0.46, 0.46, 0.485, 0.515, 0.5, 0.465, 0.465, 0.48, 0.46, 0.445, 0.43, 0.465, 0.475, 0.47, 0.465, 0.47, 0.475, 0.44, 0.465, 0.495, 0.48, 0.45, 0.445, 0.465, 0.455, 0.475, 0.49, 0.515, 0.505, 0.465, 0.475, 0.45, 0.505, 0.48, 0.48, 0.465, 0.485, 0.465, 0.45, 0.465, 0.46, 0.455, 0.445, 0.475, 0.485, 0.45, 0.435, 0.455, 0.46, 0.485, 0.47, 0.45, 0.455, 0.475, 0.44, 0.475, 0.44, 0.47, 0.48, 0.435, 0.46, 0.46, 0.485, 0.475, 0.47, 0.44, 0.475, 0.465, 0.44, 0.47, 0.475, 0.495, 0.46, 0.495, 0.465, 0.48, 0.44, 0.46, 0.445, 0.475, 0.475, 0.465, 0.46, 0.45, 0.48, 0.495, 0.465, 0.48, 0.48, 0.485, 0.43, 0.465, 0.42, 0.445, 0.46, 0.475, 0.455, 0.46, 0.49, 0.47, 0.425, 0.46, 0.48, 0.46, 0.485, 0.46, 0.48, 0.455, 0.455, 0.465, 0.47, 0.46, 0.44, 0.465, 0.44, 0.45, 0.47, 0.44, 0.45, 0.46, 0.48, 0.46, 0.44, 0.445, 0.46, 0.44, 0.47, 0.49, 0.455, 0.465, 0.445, 0.475, 0.435, 0.44, 0.44, 0.49, 0.455, 0.46, 0.43, 0.45, 0.45, 0.43, 0.465, 0.475, 0.44, 0.465, 0.465, 0.43, 0.46, 0.45, 0.45, 0.455, 0.47, 0.48, 0.47, 0.47, 0.445, 0.44, 0.425, 0.48, 0.475, 0.45, 0.465, 0.43, 0.46, 0.445, 0.45, 0.475, 0.46, 0.485, 0.44, 0.43, 0.435, 0.425, 0.475, 0.455, 0.46, 0.45, 0.44, 0.465, 0.43, 0.445, 0.45, 0.46, 0.45, 0.45, 0.465, 0.455, 0.435, 0.43, 0.455, 0.46, 0.47, 0.475, 0.465, 0.47, 0.47, 0.45, 0.44, 0.45, 0.46, 0.465, 0.465, 0.48, 0.46, 0.45, 0.425, 0.435, 0.425, 0.435, 0.455, 0.435, 0.435, 0.43, 0.445, 0.45, 0.46, 0.435, 0.46, 0.49, 0.49, 0.455, 0.44, 0.455, 0.44, 0.445, 0.46, 0.45, 0.44, 0.495, 0.45, 0.45, 0.46, 0.45, 0.465, 0.465, 0.47, 0.435, 0.44, 0.43, 0.46, 0.43, 0.41, 0.46, 0.445, 0.42, 0.41, 0.455, 0.455, 0.465, 0.47, 0.475, 0.47, 0.465, 0.445, 0.46, 0.435, 0.43, 0.415, 0.46, 0.435, 0.475, 0.475, 0.445, 0.47, 0.465, 0.475, 0.46, 0.46, 0.48, 0.47, 0.475, 0.455, 0.43, 0.45, 0.47, 0.465, 0.44, 0.455, 0.435, 0.43, 0.45, 0.47, 0.5, 0.465], finalacc: 0.54, alpha: tensor([0.0500, 0.8891, 0.7806, 0.3028, 0.3493, 0.0300, 0.0793, 0.8171])
